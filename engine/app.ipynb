{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "from keras.models import load_model\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat initialization\n",
    "model = load_model(\"chatbot_model_latest.h5\")\n",
    "intents = json.loads(open(\"custom-intents.json\").read())\n",
    "data_file = open(\"custom-intents.json\").read()\n",
    "words = pickle.load(open(\"words.pkl\", \"rb\"))\n",
    "classes = pickle.load(open(\"classes.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat functionalities\n",
    "def clean_up_sentence(sentence):\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "\n",
    "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "def bow(sentence, words, show_details=True):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # bag of words - matrix of N words, vocabulary matrix\n",
    "    bag = [0] * len(words)\n",
    "    for s in sentence_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == s:\n",
    "                # assign 1 if current word is in the vocabulary position\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print(\"found in bag: %s\" % w)\n",
    "    return np.array(bag)\n",
    "\n",
    "\n",
    "def predict_class(sentence, model):\n",
    "    # filter out predictions below a threshold\n",
    "    p = bow(sentence, words, show_details=False)\n",
    "    res = model.predict(np.array([p]))[0]\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "    return return_list\n",
    "\n",
    "\n",
    "def getResponse(ints, intents_json):\n",
    "    tag = ints[0][\"intent\"]\n",
    "    list_of_intents = intents_json[\"intents\"]\n",
    "    for i in list_of_intents:\n",
    "        if i[\"tag\"] == tag:\n",
    "            result = random.choice(i[\"responses\"])\n",
    "            break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 97ms/step\n"
     ]
    }
   ],
   "source": [
    "intent = predict_class(\"hi\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = getResponse(intent, json.loads(data_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Greetings! How can I be of service?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_response(msg):\n",
    "    ints = predict_class(msg, model)\n",
    "    res = getResponse(ints, intents)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n",
      "I was developed by Abdulmunim Jundurahman as part of a side open-source project for Addis Ababa Institute of Technology.\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Hello, {n}! What can I do for you?\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "I'm sorry, I couldn't understand your question. I am currently under heavy development and may not have answers to all questions. It will be improved over time as more data becomes available.\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "I'm sorry, I couldn't understand your question. I am currently under heavy development and may not have answers to all questions. It will be improved over time as more data becomes available.\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "I'm sorry, I couldn't understand your question. I am currently under heavy development and may not have answers to all questions. It will be improved over time as more data becomes available.\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "The AAiT Assistant Bot is continuously improving, but it may not have answers to every question. For further information, you can visit the official Addis Ababa Institute of Technology website at https://www.aaiT.edu.et/ or contact them at +251-11-232412.\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "The AAiT Assistant Bot is continuously improving, but it may not have answers to every question. For further information, you can visit the official Addis Ababa Institute of Technology website at https://www.aaiT.edu.et/ or contact them at +251-11-232412.\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "I'm sorry, I couldn't understand your question. I am currently under heavy development and may not have answers to all questions. It will be improved over time as more data becomes available.\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "The AAiT Assistant Bot is continuously improving, but it may not have answers to every question. For further information, you can visit the official Addis Ababa Institute of Technology website at https://www.aaiT.edu.et/ or contact them at +251-11-232412.\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "I'm sorry, I couldn't understand your question. I am currently under heavy development and may not have answers to all questions. It will be improved over time as more data becomes available.\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "The AAiT Assistant Bot is continuously improving, but it may not have answers to every question. For further information, you can visit the official Addis Ababa Institute of Technology website at https://www.aaiT.edu.et/ or contact them at +251-11-232412.\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "The AAiT Assistant Bot is continuously improving, but it may not have answers to every question. For further information, you can visit the official Addis Ababa Institute of Technology website at https://www.aaiT.edu.et/ or contact them at +251-11-232412.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "I'm sorry, I couldn't understand your question. I am currently under heavy development and may not have answers to all questions. It will be improved over time as more data becomes available.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Hey! What can I do for you?\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "I'm sorry, I couldn't understand your question. I am currently under heavy development and may not have answers to all questions. It will be improved over time as more data becomes available.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    message = input(\"\")\n",
    "    if message == \"quit\":\n",
    "        break\n",
    "    print(chatbot_response(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
